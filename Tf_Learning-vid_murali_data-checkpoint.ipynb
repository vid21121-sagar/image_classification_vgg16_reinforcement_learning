{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pretrained network like VGG16,ALexNet,VGG19 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mobilenet_conv = MobileNet(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze the model, No weigh update, Use Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_mobilenet_conv.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "train_data_dir = 'C:\\\\Users\\\\hp\\\\Desktop\\\\ann_self\\\\train'\n",
    "val_data_dir = 'C:\\\\Users\\\\hp\\\\Desktop\\\\ann_self\\\\val'\n",
    "model_weights_file = 'C:\\\\Users\\\\hp\\\\Desktop\\\\Fundamentals of Computer Vision and Artificial Neural Networks\\\\vgg16-xfer-weights.h5'\n",
    "nb_train_samples = 18\n",
    "nb_val_samples = 18\n",
    "nb_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a classification model on top of Base Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(img_width, img_height, 3))\n",
    "output_vgg16_conv = model_mobilenet_conv(input)\n",
    "x1 = Flatten()(output_vgg16_conv)\n",
    "x2 = Dense(64, activation='relu')(x1)\n",
    "x3 = Dense(3, activation='softmax')(x2)\n",
    "model = Model(input=input, output=x3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.training.Model object at 0x000001EFAEC5ABC8>>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 3 classes.\n",
      "Found 18 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n",
    "                                                    batch_size=3, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), \n",
    "                                                        batch_size=3,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 5s 761ms/step - loss: 9.2435 - accuracy: 0.4444 - val_loss: 3.6910 - val_accuracy: 0.5556\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 3s 540ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 5.3152 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 4s 617ms/step - loss: 1.6540 - accuracy: 0.7222 - val_loss: 4.0196 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 4s 601ms/step - loss: 0.2477 - accuracy: 0.8889 - val_loss: 4.9063 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 3s 543ms/step - loss: 0.3906 - accuracy: 0.9444 - val_loss: 1.7645 - val_accuracy: 0.5556\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 3s 544ms/step - loss: 3.1251e-05 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.6111\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 4s 595ms/step - loss: 2.3285e-04 - accuracy: 1.0000 - val_loss: 2.0214 - val_accuracy: 0.7222\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 3s 552ms/step - loss: 7.5499e-07 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.7222\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 3s 551ms/step - loss: 5.1630e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.7222\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 3s 563ms/step - loss: 6.3112e-06 - accuracy: 1.0000 - val_loss: 2.2093 - val_accuracy: 0.7222\n",
      "Training Completed!\n"
     ]
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history = model.fit_generator( train_generator, callbacks = callbacks, samples_per_epoch=nb_train_samples, \n",
    "                              nb_epoch=nb_epochs, validation_data=validation_generator, nb_val_samples=nb_val_samples)\n",
    "\n",
    "print('Training Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Array: [[9.3538880e-01 6.4426690e-02 1.8448896e-04]]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'C:\\\\Users\\\\hp\\\\Downloads\\\\WhatsApp Image 2020-01-04 at 4.37.23 AM.jpeg'\n",
    "label = ['karthik','murali','vid']\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)\n",
    "#ind = np.where(features == 1)[1][0]\n",
    "print('Predicted Array:',features)\n",
    "\n",
    "#print('Predicted Label:',label[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: karthik\n"
     ]
    }
   ],
   "source": [
    "ind = np.argmax(features)\n",
    "print('Predicted Label:',label[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
